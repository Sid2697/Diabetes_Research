{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import  scipy.misc\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L1.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L10.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L100.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L101.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L102.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L103.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L104.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L105.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L106.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L107.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L109.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L11.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L110.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L111.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L112.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L113.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L114.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L115.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L116.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L117.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L118.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L119.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L12.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L120.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L121.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L122.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L123.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L124.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L125.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L126.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L127.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L128.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L129.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L13.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L130.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L131.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L132.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L133.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L134.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L135.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L136.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L137.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L138.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L139.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L14.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L140.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L141.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L142.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L143.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L144.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L145.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L146.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L147.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L148.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L149.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L15.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L150.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L151.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L152.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L153.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L154.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L155.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L156.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L157.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L158.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L159.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L16.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L160.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L161.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L162.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L163.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L164.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L165.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L166.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L167.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L168.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L169.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L17.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L170.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L171.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L172.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L173.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L18.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L19.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L2.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L20.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L21.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L22.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L23.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L24.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L25.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L26.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L27.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L28.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L29.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L3.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L30.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L31.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L32.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L33.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L34.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L35.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L36.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L37.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L38.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L39.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L4.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L40.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L41.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L42.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L43.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L44.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L45.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L46.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L47.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L48.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L49.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L5.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L50.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L51.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L52.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L53.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L54.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L55.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L56.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L57.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L58.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L59.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L6.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L60.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L7.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L70.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L71.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L72.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L73.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L74.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L75.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L76.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L77.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L78.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L79.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L8.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L80.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L81.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L82.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L83.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L84.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L85.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L86.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L87.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L88.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L89.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L9.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L90.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L91.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L92.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L93.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L94.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L95.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L96.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L97.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L98.png\n",
      "/Users/siddhantbansal/Desktop/Type 1 (PALM)/L99.png\n",
      "/Users/siddhantbansal/Desktop/palm/L1.png\n",
      "/Users/siddhantbansal/Desktop/palm/L10.png\n",
      "/Users/siddhantbansal/Desktop/palm/L100.png\n",
      "/Users/siddhantbansal/Desktop/palm/L101.png\n",
      "/Users/siddhantbansal/Desktop/palm/L102.png\n",
      "/Users/siddhantbansal/Desktop/palm/L103.png\n",
      "/Users/siddhantbansal/Desktop/palm/L104.png\n",
      "/Users/siddhantbansal/Desktop/palm/L105.png\n",
      "/Users/siddhantbansal/Desktop/palm/L106.png\n",
      "/Users/siddhantbansal/Desktop/palm/L107.png\n",
      "/Users/siddhantbansal/Desktop/palm/L108.png\n",
      "/Users/siddhantbansal/Desktop/palm/L109.png\n",
      "/Users/siddhantbansal/Desktop/palm/L11.png\n",
      "/Users/siddhantbansal/Desktop/palm/L110.png\n",
      "/Users/siddhantbansal/Desktop/palm/L111.png\n",
      "/Users/siddhantbansal/Desktop/palm/L112.png\n",
      "/Users/siddhantbansal/Desktop/palm/L113.png\n",
      "/Users/siddhantbansal/Desktop/palm/L114.png\n",
      "/Users/siddhantbansal/Desktop/palm/L115.png\n",
      "/Users/siddhantbansal/Desktop/palm/L116.png\n",
      "/Users/siddhantbansal/Desktop/palm/L117.png\n",
      "/Users/siddhantbansal/Desktop/palm/L118.png\n",
      "/Users/siddhantbansal/Desktop/palm/L119.png\n",
      "/Users/siddhantbansal/Desktop/palm/L12.png\n",
      "/Users/siddhantbansal/Desktop/palm/L120.png\n",
      "/Users/siddhantbansal/Desktop/palm/L121.png\n",
      "/Users/siddhantbansal/Desktop/palm/L122.png\n",
      "/Users/siddhantbansal/Desktop/palm/L123.png\n",
      "/Users/siddhantbansal/Desktop/palm/L124.png\n",
      "/Users/siddhantbansal/Desktop/palm/L125.png\n",
      "/Users/siddhantbansal/Desktop/palm/L126.png\n",
      "/Users/siddhantbansal/Desktop/palm/L127.png\n",
      "/Users/siddhantbansal/Desktop/palm/L128.png\n",
      "/Users/siddhantbansal/Desktop/palm/L129.png\n",
      "/Users/siddhantbansal/Desktop/palm/L13.png\n",
      "/Users/siddhantbansal/Desktop/palm/L130.png\n",
      "/Users/siddhantbansal/Desktop/palm/L131.png\n",
      "/Users/siddhantbansal/Desktop/palm/L132.png\n",
      "/Users/siddhantbansal/Desktop/palm/L133.png\n",
      "/Users/siddhantbansal/Desktop/palm/L134.png\n",
      "/Users/siddhantbansal/Desktop/palm/L135.png\n",
      "/Users/siddhantbansal/Desktop/palm/L136.png\n",
      "/Users/siddhantbansal/Desktop/palm/L137.png\n",
      "/Users/siddhantbansal/Desktop/palm/L138.png\n",
      "/Users/siddhantbansal/Desktop/palm/L139.png\n",
      "/Users/siddhantbansal/Desktop/palm/L14.png\n",
      "/Users/siddhantbansal/Desktop/palm/L140.png\n",
      "/Users/siddhantbansal/Desktop/palm/L141.png\n",
      "/Users/siddhantbansal/Desktop/palm/L142.png\n",
      "/Users/siddhantbansal/Desktop/palm/L143.png\n",
      "/Users/siddhantbansal/Desktop/palm/L144.png\n",
      "/Users/siddhantbansal/Desktop/palm/L145.png\n",
      "/Users/siddhantbansal/Desktop/palm/L146.png\n",
      "/Users/siddhantbansal/Desktop/palm/L147.png\n",
      "/Users/siddhantbansal/Desktop/palm/L148.png\n",
      "/Users/siddhantbansal/Desktop/palm/L149.png\n",
      "/Users/siddhantbansal/Desktop/palm/L15.png\n",
      "/Users/siddhantbansal/Desktop/palm/L150.png\n",
      "/Users/siddhantbansal/Desktop/palm/L151.png\n",
      "/Users/siddhantbansal/Desktop/palm/L152.png\n",
      "/Users/siddhantbansal/Desktop/palm/L153.png\n",
      "/Users/siddhantbansal/Desktop/palm/L154.png\n",
      "/Users/siddhantbansal/Desktop/palm/L155.png\n",
      "/Users/siddhantbansal/Desktop/palm/L156.png\n",
      "/Users/siddhantbansal/Desktop/palm/L157.png\n",
      "/Users/siddhantbansal/Desktop/palm/L158.png\n",
      "/Users/siddhantbansal/Desktop/palm/L159.png\n",
      "/Users/siddhantbansal/Desktop/palm/L16.png\n",
      "/Users/siddhantbansal/Desktop/palm/L160.png\n",
      "/Users/siddhantbansal/Desktop/palm/L161.png\n",
      "/Users/siddhantbansal/Desktop/palm/L162.png\n",
      "/Users/siddhantbansal/Desktop/palm/L163.png\n",
      "/Users/siddhantbansal/Desktop/palm/L164.png\n",
      "/Users/siddhantbansal/Desktop/palm/L165.png\n",
      "/Users/siddhantbansal/Desktop/palm/L166.png\n",
      "/Users/siddhantbansal/Desktop/palm/L167.png\n",
      "/Users/siddhantbansal/Desktop/palm/L168.png\n",
      "/Users/siddhantbansal/Desktop/palm/L169.png\n",
      "/Users/siddhantbansal/Desktop/palm/L17.png\n",
      "/Users/siddhantbansal/Desktop/palm/L170.png\n",
      "/Users/siddhantbansal/Desktop/palm/L171.png\n",
      "/Users/siddhantbansal/Desktop/palm/L172.png\n",
      "/Users/siddhantbansal/Desktop/palm/L173.png\n",
      "/Users/siddhantbansal/Desktop/palm/L18.png\n",
      "/Users/siddhantbansal/Desktop/palm/L19.png\n",
      "/Users/siddhantbansal/Desktop/palm/L2.png\n",
      "/Users/siddhantbansal/Desktop/palm/L20.png\n",
      "/Users/siddhantbansal/Desktop/palm/L21.png\n",
      "/Users/siddhantbansal/Desktop/palm/L22.png\n",
      "/Users/siddhantbansal/Desktop/palm/L23.png\n",
      "/Users/siddhantbansal/Desktop/palm/L24.png\n",
      "/Users/siddhantbansal/Desktop/palm/L25.png\n",
      "/Users/siddhantbansal/Desktop/palm/L26.png\n",
      "/Users/siddhantbansal/Desktop/palm/L27.png\n",
      "/Users/siddhantbansal/Desktop/palm/L28.png\n",
      "/Users/siddhantbansal/Desktop/palm/L29.png\n",
      "/Users/siddhantbansal/Desktop/palm/L3.png\n",
      "/Users/siddhantbansal/Desktop/palm/L30.png\n",
      "/Users/siddhantbansal/Desktop/palm/L31.png\n",
      "/Users/siddhantbansal/Desktop/palm/L32.png\n",
      "/Users/siddhantbansal/Desktop/palm/L33.png\n",
      "/Users/siddhantbansal/Desktop/palm/L34.png\n",
      "/Users/siddhantbansal/Desktop/palm/L35.png\n",
      "/Users/siddhantbansal/Desktop/palm/L36.png\n",
      "/Users/siddhantbansal/Desktop/palm/L37.png\n",
      "/Users/siddhantbansal/Desktop/palm/L38.png\n",
      "/Users/siddhantbansal/Desktop/palm/L39.png\n",
      "/Users/siddhantbansal/Desktop/palm/L4.png\n",
      "/Users/siddhantbansal/Desktop/palm/L40.png\n",
      "/Users/siddhantbansal/Desktop/palm/L41.png\n",
      "/Users/siddhantbansal/Desktop/palm/L42.png\n",
      "/Users/siddhantbansal/Desktop/palm/L43.png\n",
      "/Users/siddhantbansal/Desktop/palm/L44.png\n",
      "/Users/siddhantbansal/Desktop/palm/L45.png\n",
      "/Users/siddhantbansal/Desktop/palm/L46.png\n",
      "/Users/siddhantbansal/Desktop/palm/L47.png\n",
      "/Users/siddhantbansal/Desktop/palm/L48.png\n",
      "/Users/siddhantbansal/Desktop/palm/L49.png\n",
      "/Users/siddhantbansal/Desktop/palm/L5.png\n",
      "/Users/siddhantbansal/Desktop/palm/L50.png\n",
      "/Users/siddhantbansal/Desktop/palm/L51.png\n",
      "/Users/siddhantbansal/Desktop/palm/L52.png\n",
      "/Users/siddhantbansal/Desktop/palm/L53.png\n",
      "/Users/siddhantbansal/Desktop/palm/L54.png\n",
      "/Users/siddhantbansal/Desktop/palm/L55.png\n",
      "/Users/siddhantbansal/Desktop/palm/L56.png\n",
      "/Users/siddhantbansal/Desktop/palm/L57.png\n",
      "/Users/siddhantbansal/Desktop/palm/L58.png\n",
      "/Users/siddhantbansal/Desktop/palm/L59.png\n",
      "/Users/siddhantbansal/Desktop/palm/L6.png\n",
      "/Users/siddhantbansal/Desktop/palm/L60.png\n",
      "/Users/siddhantbansal/Desktop/palm/L61.png\n",
      "/Users/siddhantbansal/Desktop/palm/L62.png\n",
      "/Users/siddhantbansal/Desktop/palm/L63.png\n",
      "/Users/siddhantbansal/Desktop/palm/L64.png\n",
      "/Users/siddhantbansal/Desktop/palm/L65.png\n",
      "/Users/siddhantbansal/Desktop/palm/L66.png\n",
      "/Users/siddhantbansal/Desktop/palm/L67.png\n",
      "/Users/siddhantbansal/Desktop/palm/L68.png\n",
      "/Users/siddhantbansal/Desktop/palm/L69.png\n",
      "/Users/siddhantbansal/Desktop/palm/L7.png\n",
      "/Users/siddhantbansal/Desktop/palm/L70.png\n",
      "/Users/siddhantbansal/Desktop/palm/L71.png\n",
      "/Users/siddhantbansal/Desktop/palm/L72.png\n",
      "/Users/siddhantbansal/Desktop/palm/L73.png\n",
      "/Users/siddhantbansal/Desktop/palm/L74.png\n",
      "/Users/siddhantbansal/Desktop/palm/L75.png\n",
      "/Users/siddhantbansal/Desktop/palm/L76.png\n",
      "/Users/siddhantbansal/Desktop/palm/L77.png\n",
      "/Users/siddhantbansal/Desktop/palm/L78.png\n",
      "/Users/siddhantbansal/Desktop/palm/L79.png\n",
      "/Users/siddhantbansal/Desktop/palm/L8.png\n",
      "/Users/siddhantbansal/Desktop/palm/L80.png\n",
      "/Users/siddhantbansal/Desktop/palm/L81.png\n",
      "/Users/siddhantbansal/Desktop/palm/L82.png\n",
      "/Users/siddhantbansal/Desktop/palm/L83.png\n",
      "/Users/siddhantbansal/Desktop/palm/L84.png\n",
      "/Users/siddhantbansal/Desktop/palm/L85.png\n",
      "/Users/siddhantbansal/Desktop/palm/L86.png\n",
      "/Users/siddhantbansal/Desktop/palm/L87.png\n",
      "/Users/siddhantbansal/Desktop/palm/L88.png\n",
      "/Users/siddhantbansal/Desktop/palm/L89.png\n",
      "/Users/siddhantbansal/Desktop/palm/L9.png\n",
      "/Users/siddhantbansal/Desktop/palm/L90.png\n",
      "/Users/siddhantbansal/Desktop/palm/L91.png\n",
      "/Users/siddhantbansal/Desktop/palm/L92.png\n",
      "/Users/siddhantbansal/Desktop/palm/L93.png\n",
      "/Users/siddhantbansal/Desktop/palm/L94.png\n",
      "/Users/siddhantbansal/Desktop/palm/L95.png\n",
      "/Users/siddhantbansal/Desktop/palm/L96.png\n",
      "/Users/siddhantbansal/Desktop/palm/L97.png\n",
      "/Users/siddhantbansal/Desktop/palm/L98.png\n",
      "/Users/siddhantbansal/Desktop/palm/L99.png\n"
     ]
    }
   ],
   "source": [
    "train=np.empty(shape=(336,450,500))\n",
    "y=[]\n",
    "counter=0\n",
    "i = 0\n",
    "for filename in glob.iglob('/Users/siddhantbansal/Desktop/Type 1 (PALM)/*.*'):\n",
    "    print(filename)\n",
    "    img=scipy.misc.imread(filename,mode='L')\n",
    "    img=scipy.misc.imresize(img,(450,500))\n",
    "    train[counter]=img\n",
    "    counter+=1\n",
    "    y.append(0)\n",
    "    i += 1\n",
    "for filename in glob.iglob('/Users/siddhantbansal/Desktop/palm/*.*'):\n",
    "    print(filename)\n",
    "    img=scipy.misc.imread(filename,mode='L')\n",
    "    img=scipy.misc.imresize(img,(450,500))\n",
    "    train[counter]=img\n",
    "    counter+=1\n",
    "    y.append(1)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "336"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "336"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "336"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1.         1.         0.99607843 ... 1.         1.         1.        ]\n",
      "  [1.         1.         0.99607843 ... 1.         1.         1.        ]\n",
      "  [1.         1.         0.99607843 ... 1.         1.         1.        ]\n",
      "  ...\n",
      "  [1.         1.         1.         ... 1.         1.         1.        ]\n",
      "  [1.         1.         1.         ... 1.         1.         1.        ]\n",
      "  [1.         1.         1.         ... 1.         1.         1.        ]]\n",
      "\n",
      " [[1.         1.         0.99607843 ... 1.         1.         1.        ]\n",
      "  [1.         1.         0.99607843 ... 1.         1.         1.        ]\n",
      "  [1.         1.         1.         ... 1.         1.         1.        ]\n",
      "  ...\n",
      "  [1.         1.         1.         ... 1.         1.         1.        ]\n",
      "  [1.         1.         1.         ... 1.         1.         1.        ]\n",
      "  [1.         1.         1.         ... 1.         1.         1.        ]]\n",
      "\n",
      " [[0.8627451  0.85098039 0.78431373 ... 0.99607843 0.99607843 0.99607843]\n",
      "  [0.88235294 0.87058824 0.80784314 ... 0.99607843 0.99607843 0.99607843]\n",
      "  [0.92156863 0.90980392 0.8627451  ... 0.99607843 0.99607843 0.99607843]\n",
      "  ...\n",
      "  [1.         1.         1.         ... 1.         1.         1.        ]\n",
      "  [1.         1.         1.         ... 1.         1.         1.        ]\n",
      "  [1.         1.         1.         ... 1.         1.         1.        ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.92941176 0.92941176 0.9254902  ... 0.92941176 0.92941176 0.93333333]\n",
      "  [0.92941176 0.92941176 0.9254902  ... 0.92941176 0.92941176 0.93333333]\n",
      "  [0.92941176 0.92941176 0.92941176 ... 0.93333333 0.93333333 0.93333333]\n",
      "  ...\n",
      "  [0.90980392 0.91372549 0.91372549 ... 0.92156863 0.92156863 0.92156863]\n",
      "  [0.90980392 0.91372549 0.91372549 ... 0.9254902  0.9254902  0.9254902 ]\n",
      "  [0.90980392 0.91372549 0.91372549 ... 0.9254902  0.9254902  0.9254902 ]]\n",
      "\n",
      " [[0.93333333 0.93333333 0.93333333 ... 0.9372549  0.93333333 0.93333333]\n",
      "  [0.93333333 0.93333333 0.93333333 ... 0.93333333 0.93333333 0.93333333]\n",
      "  [0.93333333 0.93333333 0.93333333 ... 0.93333333 0.93333333 0.93333333]\n",
      "  ...\n",
      "  [0.92156863 0.92156863 0.92156863 ... 0.9254902  0.9254902  0.9254902 ]\n",
      "  [0.9254902  0.9254902  0.9254902  ... 0.9254902  0.9254902  0.9254902 ]\n",
      "  [0.9254902  0.9254902  0.9254902  ... 0.9254902  0.9254902  0.9254902 ]]\n",
      "\n",
      " [[0.91372549 0.91372549 0.90980392 ... 0.93333333 0.93333333 0.93333333]\n",
      "  [0.91372549 0.91372549 0.91372549 ... 0.93333333 0.93333333 0.93333333]\n",
      "  [0.91372549 0.90980392 0.90980392 ... 0.92941176 0.92941176 0.93333333]\n",
      "  ...\n",
      "  [0.89803922 0.89411765 0.89411765 ... 0.8745098  0.91764706 0.92156863]\n",
      "  [0.89803922 0.89803922 0.89803922 ... 0.90588235 0.91372549 0.91372549]\n",
      "  [0.89803922 0.89803922 0.89803922 ... 0.90588235 0.90588235 0.90980392]]]\n"
     ]
    }
   ],
   "source": [
    "train = train/255\n",
    "print(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=np.array(y)\n",
    "y=y.reshape(336,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perfect   , now   having train and test  we also  need to shuffle  the data  as a good practice  for evaluation  and fiting \n",
    "from random import shuffle\n",
    "N=train.shape[0]\n",
    "ind_list = [i for i in range(N)]\n",
    "shuffle(ind_list)\n",
    "\n",
    "train_new  = train[ind_list, :,:]\n",
    "target_new = y[ind_list,]\n",
    "train=train_new\n",
    "y=target_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras import layers\n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding1D, BatchNormalization, Flatten, Conv1D\n",
    "from keras.layers import AveragePooling1D, MaxPooling1D, Dropout, GlobalMaxPooling1D, GlobalAveragePooling1D\n",
    "from keras.models import Model, Sequential\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "import keras.backend as K\n",
    "def DocumentModel(input_shape):\n",
    "    \"\"\"\n",
    "    Implementation of the HappyModel.\n",
    "\n",
    "    Arguments:\n",
    "    input_shape -- shape of the images of the dataset\n",
    "    Returns:\n",
    "    model -- a Model() instance in Keras\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    # Define the input placeholder as a tensor with shape input_shape. Think of this as your input image!\n",
    "    X_input = Input(input_shape)\n",
    "    X=Sequential()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # CONV -> BN -> RELU Block applied to X\n",
    "    X = Conv1D(32, 7, strides = 1, name = 'conv1')(X_input)\n",
    "    X = BatchNormalization(axis = 2, name = 'bn1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = Dropout(0.2)(X)\n",
    "    X = MaxPooling1D(2, name='max_pool1')(X)\n",
    "\n",
    "\n",
    "\n",
    "    # CONV -> BN -> RELU Block applied to X\n",
    "    X = Conv1D(64, 5, strides = 1, name = 'conv2')(X)\n",
    "    X = BatchNormalization(axis = 2, name = 'bn2')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = Dropout(0.2)(X)\n",
    "    X = MaxPooling1D(2, name='max_pool2')(X)\n",
    "\n",
    "\n",
    "\n",
    "    # CONV -> BN -> RELU Block applied to X\n",
    "    X = Conv1D(128, 3, strides = 1, name = 'conv3')(X)\n",
    "    X = BatchNormalization(axis = 2, name = 'bn3')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = Dropout(0.2)(X)\n",
    "    X = MaxPooling1D(2, name='max_pool3')(X)\n",
    "\n",
    "\n",
    "    # CONV -> BN -> RELU Block applied to X\n",
    "    X = Conv1D(64, 1, strides = 1, name = 'conv4')(X)\n",
    "    X = BatchNormalization(axis = 2, name = 'bn4')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = Dropout(0.2)(X)\n",
    "\n",
    "    #layer group5 4*4*32\n",
    "\n",
    "\n",
    "    X = Conv1D(32, 3, strides = 1, name = 'conv5')(X)\n",
    "    X = BatchNormalization(axis = 2, name = 'bn5')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = Dropout(0.2)(X)\n",
    "    X = MaxPooling1D(2, name='max_pool5')(X)\n",
    "\n",
    "    # FLATTEN X (means convert it to a vector) + FULLYCONNECTED\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(128, activation='sigmoid', name='fc1')(X)\n",
    "    X = Dense(32, activation='sigmoid', name='fc2')(X)\n",
    "    X = Dense(2, activation='sigmoid', name='fc3')(X)\n",
    "\n",
    "    # Create model. This creates your Keras model instance, you'll use this instance to train/test the model.\n",
    "    model = Model(inputs = X_input, outputs = X, name='DocumentModel')\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "312/312 [==============================] - 5s 15ms/step - loss: 0.5638 - acc: 0.6667\n",
      "Epoch 2/20\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.3650 - acc: 0.8878\n",
      "Epoch 3/20\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.2464 - acc: 0.9327\n",
      "Epoch 4/20\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.1889 - acc: 0.9519\n",
      "Epoch 5/20\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.1656 - acc: 0.9487\n",
      "Epoch 6/20\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.1364 - acc: 0.9679\n",
      "Epoch 7/20\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.1178 - acc: 0.9712\n",
      "Epoch 8/20\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.1087 - acc: 0.9744\n",
      "Epoch 9/20\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.0829 - acc: 0.9872\n",
      "Epoch 10/20\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.0734 - acc: 0.9872\n",
      "Epoch 11/20\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.0720 - acc: 0.9840\n",
      "Epoch 12/20\n",
      "312/312 [==============================] - 2s 6ms/step - loss: 0.0704 - acc: 0.9808\n",
      "Epoch 13/20\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.0809 - acc: 0.9808\n",
      "Epoch 14/20\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.0677 - acc: 0.9872\n",
      "Epoch 15/20\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.0586 - acc: 0.9840\n",
      "Epoch 16/20\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.0487 - acc: 0.9904\n",
      "Epoch 17/20\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.0414 - acc: 0.9936\n",
      "Epoch 18/20\n",
      "312/312 [==============================] - 2s 6ms/step - loss: 0.0366 - acc: 0.9936\n",
      "Epoch 19/20\n",
      "312/312 [==============================] - 2s 6ms/step - loss: 0.0311 - acc: 0.9968\n",
      "Epoch 20/20\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.0285 - acc: 0.9968\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13577b438>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "categorical_labels = to_categorical(y_train, num_classes=None)\n",
    "\n",
    "happyModel.fit(x = X_train, y = categorical_labels, epochs = 20, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy  0.9102564102564102\n"
     ]
    }
   ],
   "source": [
    "pred=happyModel.predict(X_test)\n",
    " \n",
    "y_classes = pred.argmax(axis=-1)\n",
    "from sklearn.metrics import   accuracy_score\n",
    "print('accuracy ' , accuracy_score(y_classes,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performing iteration number  1\n",
      "Epoch 1/20\n",
      "268/268 [==============================] - 10s 38ms/step - loss: 0.6688 - acc: 0.6082\n",
      "Epoch 2/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.5362 - acc: 0.8284\n",
      "Epoch 3/20\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 0.4078 - acc: 0.8657\n",
      "Epoch 4/20\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 0.3726 - acc: 0.8507\n",
      "Epoch 5/20\n",
      "268/268 [==============================] - 5s 18ms/step - loss: 0.2872 - acc: 0.9067\n",
      "Epoch 6/20\n",
      "268/268 [==============================] - 6s 21ms/step - loss: 0.2435 - acc: 0.9254\n",
      "Epoch 7/20\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 0.1992 - acc: 0.9328\n",
      "Epoch 8/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1557 - acc: 0.9627\n",
      "Epoch 9/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1725 - acc: 0.9328\n",
      "Epoch 10/20\n",
      "268/268 [==============================] - 4s 17ms/step - loss: 0.1482 - acc: 0.9515\n",
      "Epoch 11/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1901 - acc: 0.9216\n",
      "Epoch 12/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1383 - acc: 0.9552\n",
      "Epoch 13/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1109 - acc: 0.9627\n",
      "Epoch 14/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1261 - acc: 0.9590\n",
      "Epoch 15/20\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.0910 - acc: 0.9739\n",
      "Epoch 16/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1259 - acc: 0.9590\n",
      "Epoch 17/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.0788 - acc: 0.9701\n",
      "Epoch 18/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.0951 - acc: 0.9701\n",
      "Epoch 19/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.0930 - acc: 0.9701\n",
      "Epoch 20/20\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.0593 - acc: 0.9813\n",
      "accuracy  0.7352941176470589\n",
      "performing iteration number  2\n",
      "Epoch 1/20\n",
      "268/268 [==============================] - 8s 31ms/step - loss: 0.6661 - acc: 0.6082\n",
      "Epoch 2/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.5489 - acc: 0.8097\n",
      "Epoch 3/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.4289 - acc: 0.8545\n",
      "Epoch 4/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.3608 - acc: 0.8619\n",
      "Epoch 5/20\n",
      "268/268 [==============================] - 4s 17ms/step - loss: 0.3283 - acc: 0.8918\n",
      "Epoch 6/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.2888 - acc: 0.8881\n",
      "Epoch 7/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.2452 - acc: 0.8993\n",
      "Epoch 8/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1839 - acc: 0.9515\n",
      "Epoch 9/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1319 - acc: 0.9739\n",
      "Epoch 10/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1199 - acc: 0.9701\n",
      "Epoch 11/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1318 - acc: 0.9739\n",
      "Epoch 12/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1437 - acc: 0.9627\n",
      "Epoch 13/20\n",
      "268/268 [==============================] - 4s 17ms/step - loss: 0.1033 - acc: 0.9701\n",
      "Epoch 14/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.0762 - acc: 0.9888\n",
      "Epoch 15/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.0664 - acc: 0.9888\n",
      "Epoch 16/20\n",
      "268/268 [==============================] - 4s 17ms/step - loss: 0.0743 - acc: 0.9739\n",
      "Epoch 17/20\n",
      "268/268 [==============================] - 4s 17ms/step - loss: 0.0582 - acc: 0.9851\n",
      "Epoch 18/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.0430 - acc: 0.9963\n",
      "Epoch 19/20\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.0430 - acc: 0.9925\n",
      "Epoch 20/20\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.0734 - acc: 0.9776\n",
      "accuracy  0.5\n",
      "performing iteration number  3\n",
      "Epoch 1/20\n",
      "268/268 [==============================] - 9s 32ms/step - loss: 0.7052 - acc: 0.5037\n",
      "Epoch 2/20\n",
      "268/268 [==============================] - 5s 19ms/step - loss: 0.5922 - acc: 0.7052\n",
      "Epoch 3/20\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 0.5106 - acc: 0.7873\n",
      "Epoch 4/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.3969 - acc: 0.8433\n",
      "Epoch 5/20\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.3376 - acc: 0.8806\n",
      "Epoch 6/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.2841 - acc: 0.8993\n",
      "Epoch 7/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.2277 - acc: 0.9328\n",
      "Epoch 8/20\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.2411 - acc: 0.9142\n",
      "Epoch 9/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1329 - acc: 0.9739\n",
      "Epoch 10/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1343 - acc: 0.9664\n",
      "Epoch 11/20\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 0.1612 - acc: 0.9366\n",
      "Epoch 12/20\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 0.1864 - acc: 0.9291\n",
      "Epoch 13/20\n",
      "268/268 [==============================] - 5s 18ms/step - loss: 0.2029 - acc: 0.9254\n",
      "Epoch 14/20\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 0.1298 - acc: 0.9515\n",
      "Epoch 15/20\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 0.1068 - acc: 0.9739\n",
      "Epoch 16/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.0768 - acc: 0.9851\n",
      "Epoch 17/20\n",
      "268/268 [==============================] - 4s 17ms/step - loss: 0.0561 - acc: 0.9888\n",
      "Epoch 18/20\n",
      "268/268 [==============================] - 5s 19ms/step - loss: 0.0776 - acc: 0.9739\n",
      "Epoch 19/20\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 0.0855 - acc: 0.9739\n",
      "Epoch 20/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.0741 - acc: 0.9813\n",
      "accuracy  0.7941176470588235\n",
      "performing iteration number  4\n",
      "Epoch 1/20\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 0.7043 - acc: 0.5448\n",
      "Epoch 2/20\n",
      "268/268 [==============================] - 5s 18ms/step - loss: 0.6646 - acc: 0.5634\n",
      "Epoch 3/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.5984 - acc: 0.7649\n",
      "Epoch 4/20\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 0.5112 - acc: 0.7910\n",
      "Epoch 5/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.4261 - acc: 0.8284\n",
      "Epoch 6/20\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 0.3675 - acc: 0.8731\n",
      "Epoch 7/20\n",
      "268/268 [==============================] - 4s 17ms/step - loss: 0.3592 - acc: 0.8470\n",
      "Epoch 8/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.3232 - acc: 0.8694\n",
      "Epoch 9/20\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.2908 - acc: 0.9030\n",
      "Epoch 10/20\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.2528 - acc: 0.9104\n",
      "Epoch 11/20\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.1909 - acc: 0.9440\n",
      "Epoch 12/20\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.1937 - acc: 0.9403\n",
      "Epoch 13/20\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.1778 - acc: 0.9440\n",
      "Epoch 14/20\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.1665 - acc: 0.9440\n",
      "Epoch 15/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1450 - acc: 0.9515\n",
      "Epoch 16/20\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.1435 - acc: 0.9515\n",
      "Epoch 17/20\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.1116 - acc: 0.9701\n",
      "Epoch 18/20\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.0706 - acc: 0.9925\n",
      "Epoch 19/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.0685 - acc: 0.9888\n",
      "Epoch 20/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.0646 - acc: 0.9888\n",
      "accuracy  0.5\n",
      "performing iteration number  5\n",
      "Epoch 1/20\n",
      "268/268 [==============================] - 8s 30ms/step - loss: 0.6844 - acc: 0.5112\n",
      "Epoch 2/20\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.6100 - acc: 0.7873\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 4s 15ms/step - loss: 0.4982 - acc: 0.8209\n",
      "Epoch 4/20\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.3982 - acc: 0.8657\n",
      "Epoch 5/20\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.3433 - acc: 0.8993\n",
      "Epoch 6/20\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.3092 - acc: 0.8769\n",
      "Epoch 7/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.2589 - acc: 0.9104\n",
      "Epoch 8/20\n",
      "268/268 [==============================] - 5s 18ms/step - loss: 0.1845 - acc: 0.9552\n",
      "Epoch 9/20\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 0.1633 - acc: 0.9664\n",
      "Epoch 10/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1678 - acc: 0.9552\n",
      "Epoch 11/20\n",
      "268/268 [==============================] - 5s 19ms/step - loss: 0.1365 - acc: 0.9664\n",
      "Epoch 12/20\n",
      "268/268 [==============================] - 5s 18ms/step - loss: 0.1291 - acc: 0.9590\n",
      "Epoch 13/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1134 - acc: 0.9776\n",
      "Epoch 14/20\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 0.1112 - acc: 0.9851\n",
      "Epoch 15/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.0846 - acc: 0.9776\n",
      "Epoch 16/20\n",
      "268/268 [==============================] - 5s 20ms/step - loss: 0.0920 - acc: 0.9739\n",
      "Epoch 17/20\n",
      "268/268 [==============================] - 5s 18ms/step - loss: 0.1192 - acc: 0.9701\n",
      "Epoch 18/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1659 - acc: 0.9403\n",
      "Epoch 19/20\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 0.1057 - acc: 0.9739\n",
      "Epoch 20/20\n",
      "268/268 [==============================] - 5s 19ms/step - loss: 0.1138 - acc: 0.9664\n",
      "accuracy  0.7941176470588235\n",
      "performing iteration number  6\n",
      "Epoch 1/20\n",
      "268/268 [==============================] - 10s 37ms/step - loss: 0.6865 - acc: 0.5373\n",
      "Epoch 2/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.6036 - acc: 0.7761\n",
      "Epoch 3/20\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 0.4979 - acc: 0.8134\n",
      "Epoch 4/20\n",
      "268/268 [==============================] - 4s 17ms/step - loss: 0.4093 - acc: 0.8433\n",
      "Epoch 5/20\n",
      "268/268 [==============================] - 5s 18ms/step - loss: 0.3248 - acc: 0.8918\n",
      "Epoch 6/20\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 0.2596 - acc: 0.9254\n",
      "Epoch 7/20\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 0.2147 - acc: 0.9328\n",
      "Epoch 8/20\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 0.1945 - acc: 0.9515\n",
      "Epoch 9/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1996 - acc: 0.9403\n",
      "Epoch 10/20\n",
      "268/268 [==============================] - 5s 18ms/step - loss: 0.2281 - acc: 0.9291\n",
      "Epoch 11/20\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 0.1412 - acc: 0.9664\n",
      "Epoch 12/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1276 - acc: 0.9627\n",
      "Epoch 13/20\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 0.1017 - acc: 0.9813\n",
      "Epoch 14/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1206 - acc: 0.9701\n",
      "Epoch 15/20\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 0.1047 - acc: 0.9739\n",
      "Epoch 16/20\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 0.1207 - acc: 0.9776\n",
      "Epoch 17/20\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 0.0663 - acc: 0.9925\n",
      "Epoch 18/20\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 0.0672 - acc: 0.9851\n",
      "Epoch 19/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.0664 - acc: 0.9925\n",
      "Epoch 20/20\n",
      "268/268 [==============================] - 4s 17ms/step - loss: 0.0647 - acc: 0.9888\n",
      "accuracy  0.7205882352941176\n",
      "performing iteration number  7\n",
      "Epoch 1/20\n",
      "268/268 [==============================] - 9s 33ms/step - loss: 0.6965 - acc: 0.5485\n",
      "Epoch 2/20\n",
      "268/268 [==============================] - 4s 17ms/step - loss: 0.6201 - acc: 0.7537\n",
      "Epoch 3/20\n",
      "268/268 [==============================] - 4s 17ms/step - loss: 0.5131 - acc: 0.8246\n",
      "Epoch 4/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.4580 - acc: 0.8097\n",
      "Epoch 5/20\n",
      "268/268 [==============================] - 4s 17ms/step - loss: 0.3917 - acc: 0.8619\n",
      "Epoch 6/20\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.3351 - acc: 0.8731\n",
      "Epoch 7/20\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.3176 - acc: 0.8806\n",
      "Epoch 8/20\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.2431 - acc: 0.9291\n",
      "Epoch 9/20\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.1866 - acc: 0.9552\n",
      "Epoch 10/20\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.1785 - acc: 0.9478\n",
      "Epoch 11/20\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.1839 - acc: 0.9403\n",
      "Epoch 12/20\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.1733 - acc: 0.9440\n",
      "Epoch 13/20\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.1642 - acc: 0.9440\n",
      "Epoch 14/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1697 - acc: 0.9440\n",
      "Epoch 15/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1266 - acc: 0.9627\n",
      "Epoch 16/20\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.1548 - acc: 0.9515\n",
      "Epoch 17/20\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.1536 - acc: 0.9478\n",
      "Epoch 18/20\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.1624 - acc: 0.9478\n",
      "Epoch 19/20\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.0738 - acc: 0.9813\n",
      "Epoch 20/20\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.0625 - acc: 0.9851\n",
      "accuracy  0.7647058823529411\n",
      "performing iteration number  8\n",
      "Epoch 1/20\n",
      "268/268 [==============================] - 10s 39ms/step - loss: 0.6829 - acc: 0.5149\n",
      "Epoch 2/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.5892 - acc: 0.7873\n",
      "Epoch 3/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.4899 - acc: 0.8209\n",
      "Epoch 4/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.3926 - acc: 0.8806\n",
      "Epoch 5/20\n",
      "268/268 [==============================] - 4s 17ms/step - loss: 0.3614 - acc: 0.8731\n",
      "Epoch 6/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.3411 - acc: 0.8806\n",
      "Epoch 7/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.3163 - acc: 0.8881\n",
      "Epoch 8/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.2468 - acc: 0.9366\n",
      "Epoch 9/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.2129 - acc: 0.9366\n",
      "Epoch 10/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1479 - acc: 0.9813\n",
      "Epoch 11/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1546 - acc: 0.9627\n",
      "Epoch 12/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1779 - acc: 0.9478\n",
      "Epoch 13/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1531 - acc: 0.9478\n",
      "Epoch 14/20\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.1561 - acc: 0.9515\n",
      "Epoch 15/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.0980 - acc: 0.9813\n",
      "Epoch 16/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.0776 - acc: 0.9888\n",
      "Epoch 17/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.0813 - acc: 0.9888\n",
      "Epoch 18/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.0790 - acc: 0.9813\n",
      "Epoch 19/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.0616 - acc: 0.9888\n",
      "Epoch 20/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.0664 - acc: 0.9888\n",
      "accuracy  0.5294117647058824\n",
      "performing iteration number  9\n",
      "Epoch 1/20\n",
      "268/268 [==============================] - 10s 36ms/step - loss: 0.6775 - acc: 0.5709\n",
      "Epoch 2/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.5781 - acc: 0.7985\n",
      "Epoch 3/20\n",
      "268/268 [==============================] - 4s 17ms/step - loss: 0.4482 - acc: 0.8657\n",
      "Epoch 4/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.3966 - acc: 0.8507\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 4s 16ms/step - loss: 0.3366 - acc: 0.8881\n",
      "Epoch 6/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.2807 - acc: 0.9104\n",
      "Epoch 7/20\n",
      "268/268 [==============================] - 4s 17ms/step - loss: 0.2887 - acc: 0.8881\n",
      "Epoch 8/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.2798 - acc: 0.8881\n",
      "Epoch 9/20\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 0.1945 - acc: 0.9478\n",
      "Epoch 10/20\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 0.1660 - acc: 0.9627\n",
      "Epoch 11/20\n",
      "268/268 [==============================] - 4s 17ms/step - loss: 0.1328 - acc: 0.9701\n",
      "Epoch 12/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1338 - acc: 0.9701\n",
      "Epoch 13/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1277 - acc: 0.9664\n",
      "Epoch 14/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1433 - acc: 0.9552\n",
      "Epoch 15/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1857 - acc: 0.9291\n",
      "Epoch 16/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1584 - acc: 0.9478\n",
      "Epoch 17/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1649 - acc: 0.9440\n",
      "Epoch 18/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.0877 - acc: 0.9776\n",
      "Epoch 19/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1084 - acc: 0.9664\n",
      "Epoch 20/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1019 - acc: 0.9776\n",
      "accuracy  0.5294117647058824\n",
      "performing iteration number  10\n",
      "Epoch 1/20\n",
      "268/268 [==============================] - 10s 36ms/step - loss: 0.7567 - acc: 0.4851\n",
      "Epoch 2/20\n",
      "268/268 [==============================] - 4s 17ms/step - loss: 0.6686 - acc: 0.5522\n",
      "Epoch 3/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.6255 - acc: 0.7425\n",
      "Epoch 4/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.5638 - acc: 0.8060\n",
      "Epoch 5/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.4705 - acc: 0.8545\n",
      "Epoch 6/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.4280 - acc: 0.8321\n",
      "Epoch 7/20\n",
      "268/268 [==============================] - 5s 18ms/step - loss: 0.3323 - acc: 0.9179\n",
      "Epoch 8/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.2766 - acc: 0.9179\n",
      "Epoch 9/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.2445 - acc: 0.9254\n",
      "Epoch 10/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.2161 - acc: 0.9440\n",
      "Epoch 11/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.2083 - acc: 0.9291\n",
      "Epoch 12/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1883 - acc: 0.9403\n",
      "Epoch 13/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1620 - acc: 0.9590\n",
      "Epoch 14/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1514 - acc: 0.9664\n",
      "Epoch 15/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1465 - acc: 0.9590\n",
      "Epoch 16/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1991 - acc: 0.9403\n",
      "Epoch 17/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1729 - acc: 0.9403\n",
      "Epoch 18/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1646 - acc: 0.9515\n",
      "Epoch 19/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1414 - acc: 0.9627\n",
      "Epoch 20/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1452 - acc: 0.9440\n",
      "accuracy  0.7205882352941176\n",
      "performing iteration number  11\n",
      "Epoch 1/20\n",
      "268/268 [==============================] - 12s 46ms/step - loss: 0.6835 - acc: 0.5933\n",
      "Epoch 2/20\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 0.5689 - acc: 0.7463\n",
      "Epoch 3/20\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 0.4789 - acc: 0.8060\n",
      "Epoch 4/20\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 0.4146 - acc: 0.8507\n",
      "Epoch 5/20\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 0.4056 - acc: 0.7985\n",
      "Epoch 6/20\n",
      "268/268 [==============================] - 5s 18ms/step - loss: 0.3153 - acc: 0.8769\n",
      "Epoch 7/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.2779 - acc: 0.9179\n",
      "Epoch 8/20\n",
      "268/268 [==============================] - 5s 18ms/step - loss: 0.2163 - acc: 0.9366\n",
      "Epoch 9/20\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 0.2140 - acc: 0.9291\n",
      "Epoch 10/20\n",
      "268/268 [==============================] - 5s 18ms/step - loss: 0.2341 - acc: 0.9179\n",
      "Epoch 11/20\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 0.1646 - acc: 0.9552\n",
      "Epoch 12/20\n",
      "268/268 [==============================] - 5s 18ms/step - loss: 0.1518 - acc: 0.9478\n",
      "Epoch 13/20\n",
      "268/268 [==============================] - 5s 18ms/step - loss: 0.1197 - acc: 0.9627\n",
      "Epoch 14/20\n",
      "268/268 [==============================] - 5s 18ms/step - loss: 0.0974 - acc: 0.9776\n",
      "Epoch 15/20\n",
      "268/268 [==============================] - 4s 17ms/step - loss: 0.1443 - acc: 0.9627\n",
      "Epoch 16/20\n",
      "268/268 [==============================] - 5s 19ms/step - loss: 0.1054 - acc: 0.9627\n",
      "Epoch 17/20\n",
      "268/268 [==============================] - 4s 17ms/step - loss: 0.0836 - acc: 0.9776\n",
      "Epoch 18/20\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 0.1002 - acc: 0.9739\n",
      "Epoch 19/20\n",
      "268/268 [==============================] - 5s 18ms/step - loss: 0.0605 - acc: 0.9925\n",
      "Epoch 20/20\n",
      "268/268 [==============================] - 5s 18ms/step - loss: 0.0584 - acc: 0.9888\n",
      "accuracy  0.7941176470588235\n",
      "performing iteration number  12\n",
      "Epoch 1/20\n",
      "268/268 [==============================] - 11s 40ms/step - loss: 0.6952 - acc: 0.5224\n",
      "Epoch 2/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.6559 - acc: 0.7761\n",
      "Epoch 3/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.5689 - acc: 0.8172\n",
      "Epoch 4/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.4704 - acc: 0.8545\n",
      "Epoch 5/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.4109 - acc: 0.8619\n",
      "Epoch 6/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.3330 - acc: 0.8993\n",
      "Epoch 7/20\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 0.2598 - acc: 0.9254\n",
      "Epoch 8/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.2182 - acc: 0.9552\n",
      "Epoch 9/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.2231 - acc: 0.9328\n",
      "Epoch 10/20\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.1780 - acc: 0.9515\n",
      "Epoch 11/20\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.2050 - acc: 0.9366\n",
      "Epoch 12/20\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.1786 - acc: 0.9440\n",
      "Epoch 13/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1605 - acc: 0.9590\n",
      "Epoch 14/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1340 - acc: 0.9701\n",
      "Epoch 15/20\n",
      "268/268 [==============================] - 4s 17ms/step - loss: 0.1089 - acc: 0.9739\n",
      "Epoch 16/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.0997 - acc: 0.9813\n",
      "Epoch 17/20\n",
      "268/268 [==============================] - 4s 17ms/step - loss: 0.1241 - acc: 0.9627\n",
      "Epoch 18/20\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 0.1487 - acc: 0.9590\n",
      "Epoch 19/20\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 0.1286 - acc: 0.9627\n",
      "Epoch 20/20\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 0.1125 - acc: 0.9701\n",
      "accuracy  0.7205882352941176\n",
      "performing iteration number  13\n",
      "Epoch 1/20\n",
      "268/268 [==============================] - 14s 52ms/step - loss: 0.6654 - acc: 0.6455\n",
      "Epoch 2/20\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 0.5351 - acc: 0.8022\n",
      "Epoch 3/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.3966 - acc: 0.8843\n",
      "Epoch 4/20\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 0.3355 - acc: 0.8843\n",
      "Epoch 5/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.2756 - acc: 0.9067\n",
      "Epoch 6/20\n",
      "268/268 [==============================] - 5s 18ms/step - loss: 0.3122 - acc: 0.8806\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 4s 17ms/step - loss: 0.2355 - acc: 0.9216\n",
      "Epoch 8/20\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 0.2116 - acc: 0.9179\n",
      "Epoch 9/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1586 - acc: 0.9627\n",
      "Epoch 10/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1312 - acc: 0.9590\n",
      "Epoch 11/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1476 - acc: 0.9627\n",
      "Epoch 12/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1025 - acc: 0.9813\n",
      "Epoch 13/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1219 - acc: 0.9590\n",
      "Epoch 14/20\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 0.1038 - acc: 0.9739\n",
      "Epoch 15/20\n",
      "268/268 [==============================] - 5s 19ms/step - loss: 0.1031 - acc: 0.9739\n",
      "Epoch 16/20\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 0.0840 - acc: 0.9776\n",
      "Epoch 17/20\n",
      "268/268 [==============================] - 5s 18ms/step - loss: 0.1010 - acc: 0.9739\n",
      "Epoch 18/20\n",
      "268/268 [==============================] - 5s 18ms/step - loss: 0.1117 - acc: 0.9701\n",
      "Epoch 19/20\n",
      "268/268 [==============================] - 4s 17ms/step - loss: 0.0765 - acc: 0.9888\n",
      "Epoch 20/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.0757 - acc: 0.9813\n",
      "accuracy  0.8382352941176471\n",
      "performing iteration number  14\n",
      "Epoch 1/20\n",
      "268/268 [==============================] - 12s 44ms/step - loss: 0.6688 - acc: 0.5858\n",
      "Epoch 2/20\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 0.5991 - acc: 0.6903\n",
      "Epoch 3/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.4836 - acc: 0.8134\n",
      "Epoch 4/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.3796 - acc: 0.8657\n",
      "Epoch 5/20\n",
      "268/268 [==============================] - 5s 18ms/step - loss: 0.3199 - acc: 0.8993\n",
      "Epoch 6/20\n",
      "268/268 [==============================] - 5s 18ms/step - loss: 0.2652 - acc: 0.9216\n",
      "Epoch 7/20\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 0.2397 - acc: 0.9254\n",
      "Epoch 8/20\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 0.2107 - acc: 0.9366\n",
      "Epoch 9/20\n",
      "268/268 [==============================] - 4s 17ms/step - loss: 0.2205 - acc: 0.9254\n",
      "Epoch 10/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1975 - acc: 0.9366\n",
      "Epoch 11/20\n",
      "268/268 [==============================] - 5s 18ms/step - loss: 0.1617 - acc: 0.9590\n",
      "Epoch 12/20\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 0.1357 - acc: 0.9664\n",
      "Epoch 13/20\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 0.1420 - acc: 0.9590\n",
      "Epoch 14/20\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 0.1194 - acc: 0.9776\n",
      "Epoch 15/20\n",
      "268/268 [==============================] - 5s 18ms/step - loss: 0.1540 - acc: 0.9515\n",
      "Epoch 16/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1730 - acc: 0.9440\n",
      "Epoch 17/20\n",
      "268/268 [==============================] - 5s 19ms/step - loss: 0.0847 - acc: 0.9739\n",
      "Epoch 18/20\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 0.1001 - acc: 0.9701\n",
      "Epoch 19/20\n",
      "268/268 [==============================] - 5s 18ms/step - loss: 0.0675 - acc: 0.9851\n",
      "Epoch 20/20\n",
      "268/268 [==============================] - 5s 18ms/step - loss: 0.0575 - acc: 0.9888\n",
      "accuracy  0.6617647058823529\n",
      "performing iteration number  15\n",
      "Epoch 1/20\n",
      "268/268 [==============================] - 13s 48ms/step - loss: 0.7137 - acc: 0.5821\n",
      "Epoch 2/20\n",
      "268/268 [==============================] - 5s 18ms/step - loss: 0.6488 - acc: 0.6455\n",
      "Epoch 3/20\n",
      "268/268 [==============================] - 6s 21ms/step - loss: 0.5662 - acc: 0.7836\n",
      "Epoch 4/20\n",
      "268/268 [==============================] - 5s 20ms/step - loss: 0.4546 - acc: 0.8358\n",
      "Epoch 5/20\n",
      "268/268 [==============================] - 5s 18ms/step - loss: 0.3705 - acc: 0.8955\n",
      "Epoch 6/20\n",
      "268/268 [==============================] - 5s 19ms/step - loss: 0.3328 - acc: 0.8918\n",
      "Epoch 7/20\n",
      "268/268 [==============================] - 5s 20ms/step - loss: 0.3018 - acc: 0.8918\n",
      "Epoch 8/20\n",
      "268/268 [==============================] - 5s 18ms/step - loss: 0.2215 - acc: 0.9366\n",
      "Epoch 9/20\n",
      "268/268 [==============================] - 5s 18ms/step - loss: 0.1894 - acc: 0.9515\n",
      "Epoch 10/20\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 0.1891 - acc: 0.9291\n",
      "Epoch 11/20\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 0.1606 - acc: 0.9552\n",
      "Epoch 12/20\n",
      "268/268 [==============================] - 5s 18ms/step - loss: 0.1505 - acc: 0.9515\n",
      "Epoch 13/20\n",
      "268/268 [==============================] - 5s 18ms/step - loss: 0.1186 - acc: 0.9701\n",
      "Epoch 14/20\n",
      "268/268 [==============================] - 5s 18ms/step - loss: 0.0909 - acc: 0.9851\n",
      "Epoch 15/20\n",
      "268/268 [==============================] - 5s 19ms/step - loss: 0.0778 - acc: 0.9888\n",
      "Epoch 16/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.0644 - acc: 0.9925\n",
      "Epoch 17/20\n",
      "268/268 [==============================] - 5s 19ms/step - loss: 0.0894 - acc: 0.9813\n",
      "Epoch 18/20\n",
      "268/268 [==============================] - 5s 20ms/step - loss: 0.0616 - acc: 0.9925\n",
      "Epoch 19/20\n",
      "268/268 [==============================] - 5s 20ms/step - loss: 0.0883 - acc: 0.9813\n",
      "Epoch 20/20\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 0.0609 - acc: 0.9851\n",
      "accuracy  0.75\n",
      "performing iteration number  16\n",
      "Epoch 1/20\n",
      "268/268 [==============================] - 13s 47ms/step - loss: 0.7315 - acc: 0.5037\n",
      "Epoch 2/20\n",
      "268/268 [==============================] - 4s 17ms/step - loss: 0.6739 - acc: 0.5672\n",
      "Epoch 3/20\n",
      "268/268 [==============================] - 5s 18ms/step - loss: 0.6324 - acc: 0.7500\n",
      "Epoch 4/20\n",
      "268/268 [==============================] - 5s 19ms/step - loss: 0.5714 - acc: 0.7873\n",
      "Epoch 5/20\n",
      "268/268 [==============================] - 4s 17ms/step - loss: 0.5016 - acc: 0.7948\n",
      "Epoch 6/20\n",
      "268/268 [==============================] - 5s 18ms/step - loss: 0.4468 - acc: 0.8284\n",
      "Epoch 7/20\n",
      "268/268 [==============================] - 5s 18ms/step - loss: 0.4135 - acc: 0.8246\n",
      "Epoch 8/20\n",
      "268/268 [==============================] - 5s 18ms/step - loss: 0.4249 - acc: 0.8134\n",
      "Epoch 9/20\n",
      "268/268 [==============================] - 6s 22ms/step - loss: 0.3278 - acc: 0.8657\n",
      "Epoch 10/20\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 0.2929 - acc: 0.9067\n",
      "Epoch 11/20\n",
      "268/268 [==============================] - 4s 17ms/step - loss: 0.2654 - acc: 0.9179\n",
      "Epoch 12/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.2190 - acc: 0.9403\n",
      "Epoch 13/20\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 0.2198 - acc: 0.9366\n",
      "Epoch 14/20\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 0.2066 - acc: 0.9366\n",
      "Epoch 15/20\n",
      "268/268 [==============================] - 5s 20ms/step - loss: 0.1935 - acc: 0.9440\n",
      "Epoch 16/20\n",
      "268/268 [==============================] - 5s 18ms/step - loss: 0.1475 - acc: 0.9590\n",
      "Epoch 17/20\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 0.1227 - acc: 0.9739\n",
      "Epoch 18/20\n",
      "268/268 [==============================] - 4s 17ms/step - loss: 0.1129 - acc: 0.9776\n",
      "Epoch 19/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1694 - acc: 0.9403\n",
      "Epoch 20/20\n",
      "268/268 [==============================] - 5s 19ms/step - loss: 0.1885 - acc: 0.9328\n",
      "accuracy  0.5294117647058824\n",
      "performing iteration number  17\n",
      "Epoch 1/20\n",
      "268/268 [==============================] - 13s 48ms/step - loss: 0.6946 - acc: 0.4813\n",
      "Epoch 2/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.6110 - acc: 0.7351\n",
      "Epoch 3/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.4933 - acc: 0.8396\n",
      "Epoch 4/20\n",
      "268/268 [==============================] - 4s 17ms/step - loss: 0.4106 - acc: 0.8619\n",
      "Epoch 5/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.3556 - acc: 0.8769\n",
      "Epoch 6/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.2916 - acc: 0.8955\n",
      "Epoch 7/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.2909 - acc: 0.8843\n",
      "Epoch 8/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.2475 - acc: 0.9179\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 5s 17ms/step - loss: 0.1958 - acc: 0.9440\n",
      "Epoch 10/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1989 - acc: 0.9328\n",
      "Epoch 11/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1487 - acc: 0.9664\n",
      "Epoch 12/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1316 - acc: 0.9701\n",
      "Epoch 13/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.0943 - acc: 0.9888\n",
      "Epoch 14/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.0951 - acc: 0.9739\n",
      "Epoch 15/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1056 - acc: 0.9701\n",
      "Epoch 16/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1079 - acc: 0.9701\n",
      "Epoch 17/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1582 - acc: 0.9440\n",
      "Epoch 18/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1849 - acc: 0.9216\n",
      "Epoch 19/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.0733 - acc: 0.9813\n",
      "Epoch 20/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.0828 - acc: 0.9776\n",
      "accuracy  0.6029411764705882\n",
      "performing iteration number  18\n",
      "Epoch 1/20\n",
      "268/268 [==============================] - 16s 58ms/step - loss: 0.6970 - acc: 0.5224\n",
      "Epoch 2/20\n",
      "268/268 [==============================] - 5s 18ms/step - loss: 0.6225 - acc: 0.6866\n",
      "Epoch 3/20\n",
      "268/268 [==============================] - 5s 19ms/step - loss: 0.5118 - acc: 0.8284\n",
      "Epoch 4/20\n",
      "268/268 [==============================] - 5s 19ms/step - loss: 0.4132 - acc: 0.8619\n",
      "Epoch 5/20\n",
      "268/268 [==============================] - 4s 17ms/step - loss: 0.3405 - acc: 0.8843\n",
      "Epoch 6/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.3014 - acc: 0.8769\n",
      "Epoch 7/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.2411 - acc: 0.9142\n",
      "Epoch 8/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.2219 - acc: 0.9216\n",
      "Epoch 9/20\n",
      "268/268 [==============================] - 5s 18ms/step - loss: 0.2006 - acc: 0.9403\n",
      "Epoch 10/20\n",
      "268/268 [==============================] - 5s 19ms/step - loss: 0.1392 - acc: 0.9627\n",
      "Epoch 11/20\n",
      "268/268 [==============================] - 5s 18ms/step - loss: 0.1936 - acc: 0.9254\n",
      "Epoch 12/20\n",
      "268/268 [==============================] - 5s 18ms/step - loss: 0.1277 - acc: 0.9701\n",
      "Epoch 13/20\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 0.1022 - acc: 0.9813\n",
      "Epoch 14/20\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 0.0820 - acc: 0.9851\n",
      "Epoch 15/20\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 0.1103 - acc: 0.9701\n",
      "Epoch 16/20\n",
      "268/268 [==============================] - 5s 18ms/step - loss: 0.1088 - acc: 0.9701\n",
      "Epoch 17/20\n",
      "268/268 [==============================] - 4s 17ms/step - loss: 0.1021 - acc: 0.9701\n",
      "Epoch 18/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.0665 - acc: 0.9813\n",
      "Epoch 19/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.0570 - acc: 0.9888\n",
      "Epoch 20/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.0538 - acc: 0.9888\n",
      "accuracy  0.4852941176470588\n",
      "performing iteration number  19\n",
      "Epoch 1/20\n",
      "268/268 [==============================] - 17s 62ms/step - loss: 0.6827 - acc: 0.5821\n",
      "Epoch 2/20\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 0.5893 - acc: 0.7985\n",
      "Epoch 3/20\n",
      "268/268 [==============================] - 5s 18ms/step - loss: 0.4663 - acc: 0.8470\n",
      "Epoch 4/20\n",
      "268/268 [==============================] - 5s 19ms/step - loss: 0.4162 - acc: 0.8358\n",
      "Epoch 5/20\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 0.3311 - acc: 0.8881\n",
      "Epoch 6/20\n",
      "268/268 [==============================] - 4s 17ms/step - loss: 0.3005 - acc: 0.8881\n",
      "Epoch 7/20\n",
      "268/268 [==============================] - 5s 18ms/step - loss: 0.2667 - acc: 0.9030\n",
      "Epoch 8/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.2018 - acc: 0.9478\n",
      "Epoch 9/20\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 0.1749 - acc: 0.9440\n",
      "Epoch 10/20\n",
      "268/268 [==============================] - 5s 18ms/step - loss: 0.1643 - acc: 0.9478\n",
      "Epoch 11/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1555 - acc: 0.9627\n",
      "Epoch 12/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1210 - acc: 0.9701\n",
      "Epoch 13/20\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 0.0897 - acc: 0.9925\n",
      "Epoch 14/20\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 0.0770 - acc: 0.9888\n",
      "Epoch 15/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.0995 - acc: 0.9739\n",
      "Epoch 16/20\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 0.0939 - acc: 0.9776\n",
      "Epoch 17/20\n",
      "268/268 [==============================] - 5s 18ms/step - loss: 0.0914 - acc: 0.9776\n",
      "Epoch 18/20\n",
      "268/268 [==============================] - 4s 17ms/step - loss: 0.0717 - acc: 0.9888\n",
      "Epoch 19/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.0895 - acc: 0.9776\n",
      "Epoch 20/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.0873 - acc: 0.9739\n",
      "accuracy  0.6323529411764706\n",
      "performing iteration number  20\n",
      "Epoch 1/20\n",
      "268/268 [==============================] - 13s 48ms/step - loss: 0.6760 - acc: 0.5448\n",
      "Epoch 2/20\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.5473 - acc: 0.8396\n",
      "Epoch 3/20\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.4420 - acc: 0.8470\n",
      "Epoch 4/20\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.3647 - acc: 0.8582\n",
      "Epoch 5/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.2846 - acc: 0.9030\n",
      "Epoch 6/20\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.2662 - acc: 0.9142\n",
      "Epoch 7/20\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.1949 - acc: 0.9440\n",
      "Epoch 8/20\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.1914 - acc: 0.9366\n",
      "Epoch 9/20\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.1994 - acc: 0.9291\n",
      "Epoch 10/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1230 - acc: 0.9701\n",
      "Epoch 11/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1029 - acc: 0.9701\n",
      "Epoch 12/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1376 - acc: 0.9590\n",
      "Epoch 13/20\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.0675 - acc: 0.9925\n",
      "Epoch 14/20\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.0673 - acc: 0.9888\n",
      "Epoch 15/20\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.0534 - acc: 0.9963\n",
      "Epoch 16/20\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.0470 - acc: 0.9925\n",
      "Epoch 17/20\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.0486 - acc: 0.9925\n",
      "Epoch 18/20\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.0350 - acc: 0.9925\n",
      "Epoch 19/20\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.0287 - acc: 0.9963\n",
      "Epoch 20/20\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.0259 - acc: 1.0000\n",
      "accuracy  0.8382352941176471\n",
      "performing iteration number  21\n",
      "Epoch 1/20\n",
      "268/268 [==============================] - 17s 63ms/step - loss: 0.6878 - acc: 0.5373\n",
      "Epoch 2/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.6233 - acc: 0.7910\n",
      "Epoch 3/20\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.5381 - acc: 0.8209\n",
      "Epoch 4/20\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.4518 - acc: 0.8545\n",
      "Epoch 5/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.3692 - acc: 0.8769\n",
      "Epoch 6/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.3154 - acc: 0.9067\n",
      "Epoch 7/20\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.2657 - acc: 0.9291\n",
      "Epoch 8/20\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.2539 - acc: 0.9216\n",
      "Epoch 9/20\n",
      "268/268 [==============================] - 4s 17ms/step - loss: 0.1963 - acc: 0.9552\n",
      "Epoch 10/20\n",
      "268/268 [==============================] - 5s 18ms/step - loss: 0.1829 - acc: 0.9515\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 5s 17ms/step - loss: 0.1338 - acc: 0.9739\n",
      "Epoch 12/20\n",
      "268/268 [==============================] - 5s 18ms/step - loss: 0.1306 - acc: 0.9590\n",
      "Epoch 13/20\n",
      "268/268 [==============================] - 5s 18ms/step - loss: 0.1353 - acc: 0.9552\n",
      "Epoch 14/20\n",
      "268/268 [==============================] - 5s 18ms/step - loss: 0.1260 - acc: 0.9664\n",
      "Epoch 15/20\n",
      "268/268 [==============================] - 5s 18ms/step - loss: 0.1729 - acc: 0.9366\n",
      "Epoch 16/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.0912 - acc: 0.9701\n",
      "Epoch 17/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.0769 - acc: 0.9813\n",
      "Epoch 18/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.0627 - acc: 0.9925\n",
      "Epoch 19/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.0749 - acc: 0.9813\n",
      "Epoch 20/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.0553 - acc: 0.9888\n",
      "accuracy  0.6911764705882353\n",
      "performing iteration number  22\n",
      "Epoch 1/20\n",
      "268/268 [==============================] - 19s 70ms/step - loss: 0.6741 - acc: 0.6343\n",
      "Epoch 2/20\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 0.5677 - acc: 0.7985\n",
      "Epoch 3/20\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 0.4707 - acc: 0.8134\n",
      "Epoch 4/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.4026 - acc: 0.8321\n",
      "Epoch 5/20\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 0.3415 - acc: 0.8806\n",
      "Epoch 6/20\n",
      "268/268 [==============================] - 4s 17ms/step - loss: 0.2853 - acc: 0.8993\n",
      "Epoch 7/20\n",
      "268/268 [==============================] - 4s 17ms/step - loss: 0.2410 - acc: 0.9366\n",
      "Epoch 8/20\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 0.2068 - acc: 0.9403\n",
      "Epoch 9/20\n",
      "268/268 [==============================] - 4s 17ms/step - loss: 0.1811 - acc: 0.9515\n",
      "Epoch 10/20\n",
      "268/268 [==============================] - 5s 18ms/step - loss: 0.1599 - acc: 0.9515\n",
      "Epoch 11/20\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 0.1359 - acc: 0.9627\n",
      "Epoch 12/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1170 - acc: 0.9701\n",
      "Epoch 13/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.0809 - acc: 0.9888\n",
      "Epoch 14/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.0912 - acc: 0.9813\n",
      "Epoch 15/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.0663 - acc: 0.9925\n",
      "Epoch 16/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1197 - acc: 0.9701\n",
      "Epoch 17/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1495 - acc: 0.9552\n",
      "Epoch 18/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1581 - acc: 0.9291\n",
      "Epoch 19/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1010 - acc: 0.9701\n",
      "Epoch 20/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.0853 - acc: 0.9851\n",
      "accuracy  0.5294117647058824\n",
      "performing iteration number  23\n",
      "Epoch 1/20\n",
      "268/268 [==============================] - 17s 62ms/step - loss: 0.6898 - acc: 0.5448\n",
      "Epoch 2/20\n",
      "268/268 [==============================] - 5s 18ms/step - loss: 0.6170 - acc: 0.7612\n",
      "Epoch 3/20\n",
      "268/268 [==============================] - 5s 18ms/step - loss: 0.5183 - acc: 0.7761\n",
      "Epoch 4/20\n",
      "268/268 [==============================] - 5s 19ms/step - loss: 0.4285 - acc: 0.8358\n",
      "Epoch 5/20\n",
      "268/268 [==============================] - 5s 18ms/step - loss: 0.3812 - acc: 0.8507\n",
      "Epoch 6/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.3384 - acc: 0.8694\n",
      "Epoch 7/20\n",
      "268/268 [==============================] - 4s 17ms/step - loss: 0.2759 - acc: 0.9179\n",
      "Epoch 8/20\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 0.2198 - acc: 0.9328\n",
      "Epoch 9/20\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 0.2206 - acc: 0.9440\n",
      "Epoch 10/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1925 - acc: 0.9440\n",
      "Epoch 11/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1993 - acc: 0.9328\n",
      "Epoch 12/20\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 0.1628 - acc: 0.9515\n",
      "Epoch 13/20\n",
      "268/268 [==============================] - 4s 17ms/step - loss: 0.1598 - acc: 0.9590\n",
      "Epoch 14/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1782 - acc: 0.9403\n",
      "Epoch 15/20\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.1867 - acc: 0.9478\n",
      "Epoch 16/20\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.1722 - acc: 0.9478\n",
      "Epoch 17/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1853 - acc: 0.9291\n",
      "Epoch 18/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1079 - acc: 0.9776\n",
      "Epoch 19/20\n",
      "268/268 [==============================] - 5s 18ms/step - loss: 0.1276 - acc: 0.9739\n",
      "Epoch 20/20\n",
      "268/268 [==============================] - 5s 18ms/step - loss: 0.1015 - acc: 0.9776\n",
      "accuracy  0.7205882352941176\n",
      "performing iteration number  24\n",
      "Epoch 1/20\n",
      "268/268 [==============================] - 16s 60ms/step - loss: 0.6850 - acc: 0.5448\n",
      "Epoch 2/20\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 0.6005 - acc: 0.8060\n",
      "Epoch 3/20\n",
      "268/268 [==============================] - 4s 17ms/step - loss: 0.4736 - acc: 0.8582\n",
      "Epoch 4/20\n",
      "268/268 [==============================] - 4s 17ms/step - loss: 0.4114 - acc: 0.8545\n",
      "Epoch 5/20\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 0.3562 - acc: 0.8731\n",
      "Epoch 6/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.2949 - acc: 0.8918\n",
      "Epoch 7/20\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.2730 - acc: 0.9067\n",
      "Epoch 8/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.2317 - acc: 0.9328\n",
      "Epoch 9/20\n",
      "268/268 [==============================] - 4s 17ms/step - loss: 0.2587 - acc: 0.9067\n",
      "Epoch 10/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.2327 - acc: 0.9179\n",
      "Epoch 11/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1467 - acc: 0.9701\n",
      "Epoch 12/20\n",
      "268/268 [==============================] - 4s 17ms/step - loss: 0.1361 - acc: 0.9739\n",
      "Epoch 13/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1274 - acc: 0.9627\n",
      "Epoch 14/20\n",
      "268/268 [==============================] - 4s 17ms/step - loss: 0.1047 - acc: 0.9813\n",
      "Epoch 15/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1561 - acc: 0.9478\n",
      "Epoch 16/20\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 0.1102 - acc: 0.9739\n",
      "Epoch 17/20\n",
      "268/268 [==============================] - 4s 17ms/step - loss: 0.0900 - acc: 0.9851\n",
      "Epoch 18/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.0952 - acc: 0.9776\n",
      "Epoch 19/20\n",
      "268/268 [==============================] - 4s 17ms/step - loss: 0.0937 - acc: 0.9776\n",
      "Epoch 20/20\n",
      "268/268 [==============================] - 5s 18ms/step - loss: 0.0611 - acc: 0.9888\n",
      "accuracy  0.6911764705882353\n",
      "performing iteration number  25\n",
      "Epoch 1/20\n",
      "268/268 [==============================] - 16s 59ms/step - loss: 0.7360 - acc: 0.5037\n",
      "Epoch 2/20\n",
      "268/268 [==============================] - 5s 18ms/step - loss: 0.6624 - acc: 0.6754\n",
      "Epoch 3/20\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 0.5997 - acc: 0.8321\n",
      "Epoch 4/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.5251 - acc: 0.7985\n",
      "Epoch 5/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.4114 - acc: 0.8545\n",
      "Epoch 6/20\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 0.3624 - acc: 0.8918\n",
      "Epoch 7/20\n",
      "268/268 [==============================] - 5s 18ms/step - loss: 0.3233 - acc: 0.8843\n",
      "Epoch 8/20\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 0.2832 - acc: 0.9067\n",
      "Epoch 9/20\n",
      "268/268 [==============================] - 5s 18ms/step - loss: 0.3096 - acc: 0.8881\n",
      "Epoch 10/20\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 0.2545 - acc: 0.9216\n",
      "Epoch 11/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.2149 - acc: 0.9366\n",
      "Epoch 12/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1681 - acc: 0.9627\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 5s 19ms/step - loss: 0.1402 - acc: 0.9813\n",
      "Epoch 14/20\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 0.1698 - acc: 0.9515\n",
      "Epoch 15/20\n",
      "268/268 [==============================] - 5s 18ms/step - loss: 0.2069 - acc: 0.9328\n",
      "Epoch 16/20\n",
      "268/268 [==============================] - 4s 17ms/step - loss: 0.1671 - acc: 0.9552\n",
      "Epoch 17/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1254 - acc: 0.9776\n",
      "Epoch 18/20\n",
      "268/268 [==============================] - 4s 17ms/step - loss: 0.1423 - acc: 0.9627\n",
      "Epoch 19/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1168 - acc: 0.9701\n",
      "Epoch 20/20\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 0.1091 - acc: 0.9739\n",
      "accuracy  0.6764705882352942\n",
      "performing iteration number  26\n",
      "Epoch 1/20\n",
      "268/268 [==============================] - 17s 62ms/step - loss: 0.6621 - acc: 0.6306\n",
      "Epoch 2/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.5612 - acc: 0.7463\n",
      "Epoch 3/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.4597 - acc: 0.8284\n",
      "Epoch 4/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.4150 - acc: 0.8358\n",
      "Epoch 5/20\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.3390 - acc: 0.8806\n",
      "Epoch 6/20\n",
      "268/268 [==============================] - 5s 18ms/step - loss: 0.3486 - acc: 0.8619\n",
      "Epoch 7/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.3188 - acc: 0.8582\n",
      "Epoch 8/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.2423 - acc: 0.9030\n",
      "Epoch 9/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.2353 - acc: 0.9104\n",
      "Epoch 10/20\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 0.1830 - acc: 0.9552\n",
      "Epoch 11/20\n",
      "268/268 [==============================] - 4s 17ms/step - loss: 0.1823 - acc: 0.9403\n",
      "Epoch 12/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1450 - acc: 0.9664\n",
      "Epoch 13/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1580 - acc: 0.9590\n",
      "Epoch 14/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.0919 - acc: 0.9851\n",
      "Epoch 15/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.0761 - acc: 0.9888\n",
      "Epoch 16/20\n",
      "268/268 [==============================] - 4s 17ms/step - loss: 0.0728 - acc: 0.9851\n",
      "Epoch 17/20\n",
      "268/268 [==============================] - 4s 17ms/step - loss: 0.0611 - acc: 0.9925\n",
      "Epoch 18/20\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 0.0452 - acc: 0.9963\n",
      "Epoch 19/20\n",
      "268/268 [==============================] - 4s 17ms/step - loss: 0.1106 - acc: 0.9739\n",
      "Epoch 20/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.0679 - acc: 0.9813\n",
      "accuracy  0.4411764705882353\n",
      "performing iteration number  27\n",
      "Epoch 1/20\n",
      "268/268 [==============================] - 18s 68ms/step - loss: 0.7669 - acc: 0.5410\n",
      "Epoch 2/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.6351 - acc: 0.6791\n",
      "Epoch 3/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.5852 - acc: 0.7575\n",
      "Epoch 4/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.5098 - acc: 0.8433\n",
      "Epoch 5/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.4563 - acc: 0.8396\n",
      "Epoch 6/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.3879 - acc: 0.8657\n",
      "Epoch 7/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.3273 - acc: 0.8731\n",
      "Epoch 8/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.3013 - acc: 0.8955\n",
      "Epoch 9/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.2429 - acc: 0.9216\n",
      "Epoch 10/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.2373 - acc: 0.9179\n",
      "Epoch 11/20\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 0.2443 - acc: 0.9104\n",
      "Epoch 12/20\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.1811 - acc: 0.9627\n",
      "Epoch 13/20\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.1249 - acc: 0.9701\n",
      "Epoch 14/20\n",
      "268/268 [==============================] - 4s 17ms/step - loss: 0.1248 - acc: 0.9664\n",
      "Epoch 15/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1126 - acc: 0.9776\n",
      "Epoch 16/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1005 - acc: 0.9739\n",
      "Epoch 17/20\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 0.0853 - acc: 0.9851\n",
      "Epoch 18/20\n",
      "268/268 [==============================] - 4s 17ms/step - loss: 0.1674 - acc: 0.9515\n",
      "Epoch 19/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1737 - acc: 0.9366\n",
      "Epoch 20/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1198 - acc: 0.9627\n",
      "accuracy  0.6176470588235294\n",
      "performing iteration number  28\n",
      "Epoch 1/20\n",
      "268/268 [==============================] - 15s 57ms/step - loss: 0.6838 - acc: 0.5821\n",
      "Epoch 2/20\n",
      "268/268 [==============================] - 5s 18ms/step - loss: 0.5972 - acc: 0.7612\n",
      "Epoch 3/20\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 0.5008 - acc: 0.8284\n",
      "Epoch 4/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.4213 - acc: 0.8619\n",
      "Epoch 5/20\n",
      "268/268 [==============================] - 4s 17ms/step - loss: 0.3480 - acc: 0.8955\n",
      "Epoch 6/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.3277 - acc: 0.8955\n",
      "Epoch 7/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.2545 - acc: 0.9328\n",
      "Epoch 8/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.2155 - acc: 0.9515\n",
      "Epoch 9/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1842 - acc: 0.9590\n",
      "Epoch 10/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1888 - acc: 0.9515\n",
      "Epoch 11/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1489 - acc: 0.9701\n",
      "Epoch 12/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1269 - acc: 0.9664\n",
      "Epoch 13/20\n",
      "268/268 [==============================] - 4s 17ms/step - loss: 0.1210 - acc: 0.9701\n",
      "Epoch 14/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1309 - acc: 0.9664\n",
      "Epoch 15/20\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 0.0976 - acc: 0.9776\n",
      "Epoch 16/20\n",
      "268/268 [==============================] - 5s 19ms/step - loss: 0.0867 - acc: 0.9813\n",
      "Epoch 17/20\n",
      "268/268 [==============================] - 5s 19ms/step - loss: 0.0541 - acc: 0.9963\n",
      "Epoch 18/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.0849 - acc: 0.9776\n",
      "Epoch 19/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.0855 - acc: 0.9776\n",
      "Epoch 20/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.0857 - acc: 0.9813\n",
      "accuracy  0.6029411764705882\n",
      "performing iteration number  29\n",
      "Epoch 1/20\n",
      "268/268 [==============================] - 35s 130ms/step - loss: 0.6762 - acc: 0.5933\n",
      "Epoch 2/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.5593 - acc: 0.7836\n",
      "Epoch 3/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.4513 - acc: 0.8470\n",
      "Epoch 4/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.3912 - acc: 0.8507\n",
      "Epoch 5/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.3734 - acc: 0.8358\n",
      "Epoch 6/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.3498 - acc: 0.8694\n",
      "Epoch 7/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.2642 - acc: 0.9216\n",
      "Epoch 8/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.2354 - acc: 0.9179\n",
      "Epoch 9/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1766 - acc: 0.9552\n",
      "Epoch 10/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1337 - acc: 0.9813\n",
      "Epoch 11/20\n",
      "268/268 [==============================] - 4s 17ms/step - loss: 0.1037 - acc: 0.9776\n",
      "Epoch 12/20\n",
      "268/268 [==============================] - 4s 17ms/step - loss: 0.1481 - acc: 0.9515\n",
      "Epoch 13/20\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 0.1465 - acc: 0.9590\n",
      "Epoch 14/20\n",
      "268/268 [==============================] - 4s 17ms/step - loss: 0.1127 - acc: 0.9701\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1082 - acc: 0.9739\n",
      "Epoch 16/20\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.0834 - acc: 0.9776\n",
      "Epoch 17/20\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.0778 - acc: 0.9813\n",
      "Epoch 18/20\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.0774 - acc: 0.9813\n",
      "Epoch 19/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.0664 - acc: 0.9851\n",
      "Epoch 20/20\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.1463 - acc: 0.9403\n",
      "accuracy  0.5441176470588235\n",
      "performing iteration number  30\n",
      "Epoch 1/20\n",
      "268/268 [==============================] - 20s 75ms/step - loss: 0.6819 - acc: 0.6231\n",
      "Epoch 2/20\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 0.6022 - acc: 0.6866\n",
      "Epoch 3/20\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 0.5015 - acc: 0.8060\n",
      "Epoch 4/20\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 0.4213 - acc: 0.8470\n",
      "Epoch 5/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.3775 - acc: 0.8619\n",
      "Epoch 6/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.3759 - acc: 0.8507\n",
      "Epoch 7/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.3070 - acc: 0.9067\n",
      "Epoch 8/20\n",
      "268/268 [==============================] - 5s 17ms/step - loss: 0.2704 - acc: 0.9067\n",
      "Epoch 9/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.2308 - acc: 0.9366\n",
      "Epoch 10/20\n",
      "268/268 [==============================] - 5s 18ms/step - loss: 0.2393 - acc: 0.9216\n",
      "Epoch 11/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.2260 - acc: 0.9216\n",
      "Epoch 12/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.2144 - acc: 0.9291\n",
      "Epoch 13/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1646 - acc: 0.9590\n",
      "Epoch 14/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1678 - acc: 0.9627\n",
      "Epoch 15/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1358 - acc: 0.9664\n",
      "Epoch 16/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1254 - acc: 0.9664\n",
      "Epoch 17/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1201 - acc: 0.9701\n",
      "Epoch 18/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1340 - acc: 0.9664\n",
      "Epoch 19/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1452 - acc: 0.9590\n",
      "Epoch 20/20\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1120 - acc: 0.9776\n",
      "accuracy  0.6617647058823529\n",
      "performing iteration number  31\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-97d4bb787f96>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnp_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mcategorical_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mhappyModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcategorical_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mpred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhappyModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0my_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1667\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1668\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1669\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1671\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1204\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1206\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1207\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1208\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2471\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2472\u001b[0m         \u001b[0mfetches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates_op\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2473\u001b[0;31m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m   2475\u001b[0m                               **self.session_kwargs)\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0;31m# not already marked as initialized.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m                 is_initialized = session.run(\n\u001b[0;32m--> 189\u001b[0;31m                     [tf.is_variable_initialized(v) for v in candidate_vars])\n\u001b[0m\u001b[1;32m    190\u001b[0m                 \u001b[0muninitialized_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_initialized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1128\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1129\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1344\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1345\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1348\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1318\u001b[0m                 run_metadata):\n\u001b[1;32m   1319\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1320\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1321\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1379\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1380\u001b[0m           tf_session.TF_ExtendGraph(\n\u001b[0;32m-> 1381\u001b[0;31m               self._session, graph_def.SerializeToString(), status)\n\u001b[0m\u001b[1;32m   1382\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_opened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "scores=[]\n",
    "for i in range(50):\n",
    "    print(\"performing iteration number \", i+1)\n",
    "    \n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(train, y, test_size=0.2, random_state=i)\n",
    "    happyModel = DocumentModel(((450,500)))\n",
    "    happyModel.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
    "    from keras.utils.np_utils import to_categorical\n",
    "    categorical_labels = to_categorical(y_train, num_classes=None)\n",
    "    happyModel.fit(x = X_train, y = categorical_labels, epochs = 20, batch_size = 32)\n",
    "    pred=happyModel.predict(X_test)\n",
    "    y_classes = pred.argmax(axis=-1)\n",
    "    from sklearn.metrics import   accuracy_score\n",
    "    scores.append(accuracy_score(y_classes,y_test))\n",
    "    print('accuracy ' , accuracy_score(y_classes,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean scores 0.6539215686274508\n",
      "Max score 0.8382352941176471\n",
      "Standard Deviation 0.11230091530625921\n"
     ]
    }
   ],
   "source": [
    "print('Mean scores', np.mean(scores))\n",
    "print('Max score', np.max(scores))\n",
    "print(\"Standard Deviation\", np.std(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 hz 0.01 duty cycle 1 V min output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
